#!/usr/bin/env node

/**
 * Comprehensive Production Readiness Test
 * Tests all voice chat components end-to-end
 */

const https = require('https');
const WebSocket = require('ws');

const PRODUCTION_FRONTEND = 'https://isaac-mineo.vercel.app';
const PRODUCTION_BACKEND = 'https://isaac-mineo-api.onrender.com';

console.log('ğŸ” COMPREHENSIVE PRODUCTION READINESS TEST');
console.log('===========================================');
console.log(`Frontend: ${PRODUCTION_FRONTEND}`);
console.log(`Backend: ${PRODUCTION_BACKEND}`);
console.log('');

async function testAudioWorkletAccessibility() {
    console.log('1. ğŸµ Testing AudioWorklet Processor Accessibility...');
    
    return new Promise((resolve) => {
        const url = `${PRODUCTION_FRONTEND}/voice-audio-processor.js`;
        console.log(`   Checking: ${url}`);
        
        https.get(url, (res) => {
            let data = '';
            res.on('data', chunk => data += chunk);
            res.on('end', () => {
                if (res.statusCode === 200) {
                    console.log('   âœ… AudioWorklet processor accessible');
                    console.log(`   ğŸ“¦ Size: ${data.length} bytes`);
                    
                    // Check for key components
                    const hasProcessor = data.includes('VoiceAudioProcessor');
                    const hasRegister = data.includes('registerProcessor');
                    const hasAudioData = data.includes('audioData');
                    
                    console.log(`   ğŸ—ï¸ Has processor class: ${hasProcessor ? 'âœ…' : 'âŒ'}`);
                    console.log(`   ğŸ“ Has registration: ${hasRegister ? 'âœ…' : 'âŒ'}`);
                    console.log(`   ğŸ¤ Has audio processing: ${hasAudioData ? 'âœ…' : 'âŒ'}`);
                    
                    resolve({
                        accessible: true,
                        valid: hasProcessor && hasRegister && hasAudioData,
                        size: data.length
                    });
                } else {
                    console.log(`   âŒ AudioWorklet not accessible: ${res.statusCode}`);
                    resolve({ accessible: false, status: res.statusCode });
                }
            });
        }).on('error', (err) => {
            console.log(`   âŒ AudioWorklet fetch error: ${err.message}`);
            resolve({ accessible: false, error: err.message });
        });
    });
}

async function testVoiceServiceStatus() {
    console.log('\n2. ğŸ¯ Testing Voice Service Status...');
    
    return new Promise((resolve) => {
        https.get(`${PRODUCTION_BACKEND}/api/voice/status`, (res) => {
            let data = '';
            res.on('data', chunk => data += chunk);
            res.on('end', () => {
                try {
                    const status = JSON.parse(data);
                    console.log('   ğŸ“Š Voice Service Status:');
                    console.log(`   - Voice Enabled: ${status.voice_enabled ? 'âœ…' : 'âŒ'}`);
                    console.log(`   - Deepgram Available: ${status.deepgram_available ? 'âœ…' : 'âŒ'}`);
                    console.log(`   - ElevenLabs Available: ${status.elevenlabs_available ? 'âœ…' : 'âŒ'}`);
                    console.log(`   - Status: ${status.status}`);
                    
                    resolve({
                        working: status.voice_enabled && status.deepgram_available && status.elevenlabs_available,
                        details: status
                    });
                } catch (e) {
                    console.log(`   âŒ Invalid response: ${e.message}`);
                    resolve({ working: false, error: e.message });
                }
            });
        }).on('error', (err) => {
            console.log(`   âŒ Status check failed: ${err.message}`);
            resolve({ working: false, error: err.message });
        });
    });
}

async function testWebSocketVoiceChat() {
    console.log('\n3. ğŸ”Œ Testing WebSocket Voice Chat...');
    
    return new Promise((resolve) => {
        const wsUrl = 'wss://isaac-mineo-api.onrender.com/api/voice/chat';
        console.log(`   Connecting to: ${wsUrl}`);
        
        const ws = new WebSocket(wsUrl);
        let receivedMessages = [];
        let timeout;
        
        ws.on('open', () => {
            console.log('   âœ… WebSocket connected');
            
            // Start session
            ws.send(JSON.stringify({
                type: 'start_session',
                session_id: `readiness_test_${Date.now()}`
            }));
            
            timeout = setTimeout(() => {
                console.log('   â±ï¸ Test timeout');
                ws.close();
                resolve({
                    connected: true,
                    messages: receivedMessages,
                    voiceReady: receivedMessages.some(m => m.type === 'status' && m.voice_enabled)
                });
            }, 8000);
        });
        
        ws.on('message', (data) => {
            const message = JSON.parse(data.toString());
            receivedMessages.push(message);
            console.log(`   ğŸ“¨ Received: ${message.type} - ${message.message || 'no message'}`);
            
            if (message.type === 'status' && message.voice_enabled) {
                console.log('   âœ… Voice chat ready');
                
                // Test transcript processing
                ws.send(JSON.stringify({
                    type: 'process_transcript',
                    text: 'Production readiness test message',
                    session_id: `readiness_test_${Date.now()}`
                }));
            } else if (message.type === 'ai_response') {
                console.log('   âœ… AI response received');
                clearTimeout(timeout);
                ws.close();
                resolve({
                    connected: true,
                    messages: receivedMessages,
                    voiceReady: true,
                    aiWorking: true
                });
            }
        });
        
        ws.on('error', (error) => {
            console.log(`   âŒ WebSocket error: ${error.message}`);
            clearTimeout(timeout);
            resolve({ connected: false, error: error.message });
        });
        
        ws.on('close', () => {
            console.log('   ğŸ”Œ WebSocket closed');
            clearTimeout(timeout);
        });
    });
}

async function testAudioSynthesis() {
    console.log('\n4. ğŸµ Testing Audio Synthesis...');
    
    return new Promise((resolve) => {
        const postData = JSON.stringify({
            text: 'Production readiness test for audio synthesis.',
            session_id: `audio_test_${Date.now()}`,
            return_audio: true
        });
        
        const options = {
            hostname: 'isaac-mineo-api.onrender.com',
            port: 443,
            path: '/api/voice/synthesize',
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Content-Length': Buffer.byteLength(postData)
            }
        };
        
        const req = https.request(options, (res) => {
            let data = '';
            res.on('data', chunk => data += chunk);
            res.on('end', () => {
                try {
                    const response = JSON.parse(data);
                    console.log('   âœ… Audio synthesis working');
                    console.log(`   ğŸ“ Response length: ${response.text ? response.text.length : 0} chars`);
                    console.log(`   ğŸ”Š Audio URL provided: ${!!response.audio_url}`);
                    resolve({ working: true, response });
                } catch (e) {
                    console.log(`   âŒ Invalid response: ${e.message}`);
                    resolve({ working: false, error: e.message });
                }
            });
        });
        
        req.on('error', (err) => {
            console.log(`   âŒ Request failed: ${err.message}`);
            resolve({ working: false, error: err.message });
        });
        
        req.write(postData);
        req.end();
    });
}

async function runComprehensiveTest() {
    console.log('ğŸš€ Starting comprehensive production readiness test...\n');
    
    // Run all tests
    const audioWorkletResult = await testAudioWorkletAccessibility();
    const voiceStatusResult = await testVoiceServiceStatus();
    const webSocketResult = await testWebSocketVoiceChat();
    const audioSynthResult = await testAudioSynthesis();
    
    // Generate report
    console.log('\nğŸ“‹ PRODUCTION READINESS REPORT');
    console.log('==============================');
    
    console.log(`\nğŸµ AudioWorklet Processor:`);
    console.log(`   Accessible: ${audioWorkletResult.accessible ? 'âœ…' : 'âŒ'}`);
    console.log(`   Valid Content: ${audioWorkletResult.valid ? 'âœ…' : 'âŒ'}`);
    if (audioWorkletResult.size) console.log(`   File Size: ${audioWorkletResult.size} bytes`);
    
    console.log(`\nğŸ¯ Backend Voice Services:`);
    console.log(`   Voice Enabled: ${voiceStatusResult.working ? 'âœ…' : 'âŒ'}`);
    if (voiceStatusResult.details) {
        console.log(`   Deepgram: ${voiceStatusResult.details.deepgram_available ? 'âœ…' : 'âŒ'}`);
        console.log(`   ElevenLabs: ${voiceStatusResult.details.elevenlabs_available ? 'âœ…' : 'âŒ'}`);
    }
    
    console.log(`\nğŸ”Œ WebSocket Voice Chat:`);
    console.log(`   Connection: ${webSocketResult.connected ? 'âœ…' : 'âŒ'}`);
    console.log(`   Voice Ready: ${webSocketResult.voiceReady ? 'âœ…' : 'âŒ'}`);
    console.log(`   AI Response: ${webSocketResult.aiWorking ? 'âœ…' : 'âŒ'}`);
    
    console.log(`\nğŸµ Audio Synthesis:`);
    console.log(`   Working: ${audioSynthResult.working ? 'âœ…' : 'âŒ'}`);
    
    // Overall assessment
    const allSystemsReady = 
        audioWorkletResult.accessible && audioWorkletResult.valid &&
        voiceStatusResult.working &&
        webSocketResult.connected && webSocketResult.voiceReady && webSocketResult.aiWorking &&
        audioSynthResult.working;
    
    console.log(`\nğŸ¯ OVERALL PRODUCTION READINESS:`);
    if (allSystemsReady) {
        console.log('âœ… ALL SYSTEMS READY FOR PRODUCTION');
        console.log('ğŸ¤ Voice chat should work reliably with:');
        console.log('   - Real microphone input via AudioWorkletNode');
        console.log('   - Live transcription via Deepgram WebSocket');
        console.log('   - AI responses via OpenAI');
        console.log('   - Audio synthesis via ElevenLabs');
    } else {
        console.log('âš ï¸  SOME ISSUES DETECTED');
        if (!audioWorkletResult.accessible || !audioWorkletResult.valid) {
            console.log('âŒ AudioWorklet processor issues - will use fallback');
        }
        if (!voiceStatusResult.working) {
            console.log('âŒ Backend voice services not ready');
        }
        if (!webSocketResult.connected || !webSocketResult.voiceReady) {
            console.log('âŒ WebSocket voice chat not ready');
        }
        if (!audioSynthResult.working) {
            console.log('âŒ Audio synthesis not working');
        }
    }
    
    return {
        audioWorklet: audioWorkletResult,
        voiceStatus: voiceStatusResult,
        webSocket: webSocketResult,
        audioSynth: audioSynthResult,
        ready: allSystemsReady
    };
}

// Run the test
runComprehensiveTest().then(results => {
    console.log('\nğŸ Test completed!');
    if (results.ready) {
        console.log('ğŸ‰ Production voice chat is ready to go!');
    } else {
        console.log('ğŸ”§ Some components need attention before production use.');
    }
});
